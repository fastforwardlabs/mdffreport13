## Introduction

In recent years, machine learning has made remarkable progress, providing novel capabilities like the creation of sophisticated, computable representations of text and images. These capabilities have enabled new products, such as image search based on the image content, automatic translation between many languages, and even synthesis of realistic images and voice. Simultaneously, machine learning has seen widespread adoption in the enterprise for classic use-cases, for instance, predicting customer churn, loan defaulting and manufacturing equipment failure. Where machine learning has been successful, it has been extraordinarily so.

In many cases, that success can be attributed to supervised learning on large volumes of training data (combined with extensive computation). Broadly, supervised learning systems excel at one task: _prediction_. When the goal is to predict an outcome, and we have many examples of that outcome arising, and the features associated with it, we may turn to supervised learning.

As machine learning has gained popularity, its sphere of influence in business processes has expanded beyond narrow prediction, and into decision making. The results of machine learning systems are routinely used to set credit limits, anticipate manufacturing equipment failures and curate our various news feeds. As businesses learn from the information provided by such systems, healthy developments have been made to provide interpretability into the complex algorithms used to tackle nonlinear and high-dimensional problems.

However, there are fundamental limits to reasoning based on prediction alone. For instance, what will happen if a bank increases a customer’s credit limit? Such questions cannot be answered by a correlative model built on previously observed data, because they involve a change in the customer choices in reaction to the change in credit limit. In many cases, the outcome of our decision process is an _intervention_ - an action that changes something in the world. As we’ll demonstrate in this report, purely correlative predictive systems are not equipped for reasoning under such interventions, and hence are prone to biases. For data-informed decision making under intervention, we need causality.

Even for purely predictive systems, very much the forte of supervised learning, applying some causal thinking brings benefits. Causal relationships are by their definition _invariant_, meaning they hold true across different circumstances and environments. This is a very desirable property for machine learning systems, where we often predict on data that we have not seen in training, and need them to be adaptable and robust.

The intersection of causal inference and machine learning is a rapidly expanding area of research. It is already yielding capabilities that are ready for mainstream adoption, and which can help us build more robust, reliable and fair machine learning systems.

This report introduces the reader to causal reasoning as it pertains to much data science and machine learning work. We introduce causal graphs, with a focus on removing the _conceptual_ barriers to understanding. We then use this understanding to explore recent ideas around _invariant prediction_, which brings some of the benefits of causal graphs to high dimensional problems. Along with the accompanying prototype, we show how even classic machine learning problems, like image classification, can benefit from the tools of causal inference.